{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCbrLPyKnMmR"
   },
   "source": [
    "# 한국어 뉴스 기사분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptmpqK_6nMmT"
   },
   "source": [
    "- BalancedNewsCorpus_train.csv, BalancedNewsCorpus_test.csv는 국어원 뉴스 자료에서 9개 분야의 신문별 균형을 맞춘 자료로, 학습용 9,000개 시험용 1800 자료가 있는 파일이다.\n",
    "- 이 파일을 가지고 https://github.com/bentrevett/pytorch-sentiment-analysis 에 있는 pytorch sentiment analysis의 방법을 따라 한국어 뉴스기사 분류기를 만들어라\n",
    "- training data에서 evaluation data를 나누어 사용할 수 있다.(필요시)\n",
    "- 화일 이름은 MidTermProject_학번_이름\n",
    "- 마감: 2022년 10월 27일 목요일 오후 11시 59분 59초까지!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiN0WY4snMmU"
   },
   "source": [
    "## 목표\n",
    "\n",
    "- csv 파일을 읽어서 torchtext를 사용하여 데이터를 신경망에 입력가능한 꼴로 바꾸기\n",
    "(Field, Iterator, train,test, evaluation and prediction)\n",
    "- 한국어 데이터 전처리를 위한 함수를 만들고 이를 torchtext에 통합하기 \n",
    "\n",
    "- 외부에서 학습된 한국어 단어 임베딩을 torchtext에 통합하여 사용하기 (word2vec, glove, fasttext 중 골라서 사용)\n",
    "- 제시된 여러 모델을 사용하여(transformers 제외) 성능을 향상 시키기\n",
    "- training, evaluation 한 것을 test 데이터에 적용하여 성능을 보이기.\n",
    "- predict를 사용하여 제시된 기사들의 분류 결과를 보이기\n",
    "\n",
    "- 참고 사이트\n",
    "    - https://pytorch.org/text/\n",
    "    - http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "    - https://github.com/pytorch/text\n",
    "    - https://mc.ai/using-fine-tuned-gensim-word2vec-embeddings-with-torchtext-and-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bfui9iGnMmU"
   },
   "source": [
    "## 이 자료를 위해 사전학습된 임베딩\n",
    "- 필요에 따라 선택하여 사용할 수 있음\n",
    "\n",
    "### Word2vec 모델\n",
    " - 노트 : https://drive.google.com/file/d/1KOv901TPv5gepEdd4cCsJWoCHVaAV-A-/view?usp=sharing\n",
    " - Word2Vec 형태소 모델 : https://drive.google.com/file/d/1DDx6lRSTVULRFP3kslQLZsuoGZJOtoR1/view?usp=sharing\n",
    " - Word2Vec 어절 모델 : https://drive.google.com/file/d/1-RuEk-MhULduAbizgt3wjsMOCL3sM_pl/view?usp=sharing\n",
    "\n",
    "- from gensim.models.keyedvectors import KeyedVectors\n",
    "- Word2Vec_300D_space_model = KeyedVectors.load_word2vec_format(path + 'Word2Vec_300D_space.model', binary=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "### Faxttext 모델\n",
    "\n",
    "- fasttext 형태소 모델: https://drive.google.com/file/d/1-EBaAtFK7chB6qqckKmLdghR62SebEYK/view?usp=sharing\n",
    "- fasttext 어절 모델: https://drive.google.com/file/d/1-0D7Fe5oG_z9pQqOjkewtsuV_uVkh_dF/view?usp=sharing\n",
    "- fasttext 형태소 자모 모델: https://drive.google.com/file/d/1-WW_qWQZ2q3Jj9fXXex82dYHWIMHGVri/view?usp=sharing\n",
    "- fasttext 어절 자모 모델: https://drive.google.com/file/d/1-P2b8Dp09fZYO2Y__wjPNmS77PF7kfqV/view?usp=sharing\n",
    "\n",
    "\n",
    "- from gensim.models.keyedvectors import KeyedVectors\n",
    "- fasttext_model2 = KeyedVectors.load_word2vec_format(path + 'fasttext_morph_300.model', binary=False, encoding='utf-8')\n",
    "\n",
    "## Glove 모델\n",
    "\n",
    "- https://drive.google.com/drive/folders/1pzVO0jwx1Zf8p4hjf4JQn81XWzktsIdg?usp=sharing \n",
    "\n",
    "\n",
    "- from gensim.models.keyedvectors import KeyedVectors\n",
    "- Glove_model = KeyedVectors.load_word2vec_format(# 모델 경로 , binary=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKu8_GeGnMmV"
   },
   "source": [
    "## 정리\n",
    "### 설계 요약\n",
    "FastText 형태소 모델을 사용하였으며, 불용어 제거 및 문단 구분 태그 `<p>`와 `</p>`를 제거하는 전처리를 진행하였다.\n",
    "이러한 선택은 Word2Vec에 비해 FastText의 분류 성능이나 강건성 측면에서 나으며, 어절 토큰보다 형태소 토큰을 기반으로 하였을 때 분류 성능이 높다는 기존 연구 결과[1]를 참고하여 진행하였다.\n",
    "\n",
    "학습은 CNN으로 하였고, 2, 3, 4 높이의 필터를 각각 100개씩 사용하여 총 300개의 n-gram을 사용한 효과를 내었다.\n",
    "11번째 epoch에서 최소 validation loss를 달성하였고, 테스트 데이터에 대해서 loss는 0.575, accuracy는 80.06%가 나왔다.\n",
    "\n",
    "[1] 박서윤, 강예지, 강혜린, 장연지, 김한샘, 관용표현 중의성 해소를 위한 다층위 임베딩 연구, 제33회 한글 및 한국어 정보처리 학술대회 논문집, 2021\n",
    "\n",
    "### 성능 및 평가\n",
    "| 예상      | 답안      | 정답    |\n",
    "|-----------|-----------|---------|\n",
    "| 스포츠    | 생활      | X       |\n",
    "| 정치      | 정치      | O       |\n",
    "| 사회      | 경제      | X       |\n",
    "| 문화      | 문화      | O       |\n",
    "| 생활      | 사회      | X       |\n",
    "| 스포츠    | 스포츠    | O       |\n",
    "| 문화      | 연예      | X       |\n",
    "| 미용/사회 | 미용/사회 | O       |\n",
    "| IT/과학   | IT/과학   | O       |\n",
    "|           |           | 5/9=56% |\n",
    "        \n",
    "참고로, 무작위 예측기가 이보다 성능이 좋을 확률은\n",
    "$$\\sum_{k=5}^{9} {9 \\choose k} \\left(\\frac{1}{9}\\right)^k \\left(\\frac{8}{9}\\right)^{9-k} = 1.45\\%$$\n",
    "이다.\n",
    "\n",
    "나아가, 본인도 해당 문장들 중 두 개를 잘 못 분류할 정도로 까다로운 경우가 존재하였다.\n",
    "예컨대 \"정부는 2012년 예산의 공고안과 배정계획을 1월3일 국무회의에서 의결하고 연초부터 바로 집행에 들어간다.\n",
    "세계 경제의 불확실성이 높아지고 경기가 둔화할 가능성이 높은 만큼 조기 집행에 박차를 가할 예정이다\"은 경제라고 생각하였지만 답은 정치였고, 놀랍게도 학습된 모델은 이를 정확히 예측하였다.\n",
    "모델이 틀린 답을 내놓은 문장들을 보면 실제로는 \"생활\" 분류의 기사이지만 \"국가 대표팀\"이 등장하는 등 실제로 어려운 경우에 해당하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "KwFE5v1hXYBA"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install pandas\n",
    "# !pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install torchtext==0.9.0\n",
    "# !pip install ipywidgets\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Z2_jV3biXYBB"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "# !bash Mecab-ko-for-Google-Colab/install_mecab-ko_on_colab_light_220429.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "xl6_aFOba2hf"
   },
   "outputs": [],
   "source": [
    "PATH = \".\"  # \"./drive/MyDrive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "B3ksMMfInMmV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "data_set = f\"{PATH}/BalancedNewsCorpus_\" # test.csv / train.csv\n",
    "test_df, train_df = (pd.read_csv(f\"{data_set}{x}.csv\") for x in (\"test\", \"train\"))\n",
    "test_df, train_df = (\n",
    "    df.rename(columns={\"NewsPaper\": \"newspaper\", \"News\": \"text\", \"Topic\": \"label\"})\n",
    "    for df in (test_df, train_df)\n",
    ")\n",
    "test_df, train_df = (df.drop(columns=[\"filename\", \"date\", \"newspaper\"]) for df in (test_df, train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "-zF57j1cvx7G"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "from torchtext.legacy.data import TabularDataset\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "IZkOBm_hwCJZ"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(\n",
    "    sequential = True,\n",
    "    lower = True,\n",
    "    use_vocab = True,\n",
    "    tokenize = tokenizer.morphs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTR0PL_oXYBE",
    "outputId": "ca5f268d-fb99-4013-c214-22134c572baa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'IT/과학': 0,\n",
       "             '경제': 1,\n",
       "             '문화': 2,\n",
       "             '미용/건강': 3,\n",
       "             '사회': 4,\n",
       "             '생활': 5,\n",
       "             '스포츠': 6,\n",
       "             '연예': 7,\n",
       "             '정치': 8})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL = data.LabelField()\n",
    "LABEL.build_vocab(train_df.label)\n",
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "prog = re.compile(r\"</?p>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L2w59pugXYBF",
    "outputId": "a57a417b-107a-41ce-b420-9dc825037fa9"
   },
   "outputs": [],
   "source": [
    "# https://bab2min.tistory.com/544\n",
    "stop_words = set(pd.read_table(f\"{PATH}/stopwords-ko-100.txt\", header=None)[0])\n",
    "def preprocess(text):\n",
    "    lst = TEXT.preprocess(re.sub(prog, \"\", text))\n",
    "    return [word for word in lst if word not in stop_words]\n",
    "\n",
    "for df in (test_df, train_df):\n",
    "    df.text = df.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IT/과학</td>\n",
       "      <td>[인터넷, 게임, 족쇄, 에, 도내, 업체, 도, ‘, 덜덜, ’, 道, ㆍ업체, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IT/과학</td>\n",
       "      <td>[삼성전자, ,, un, 에, 삼, 성만, 의, 특화, 된, 생태, 보전, 활동, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT/과학</td>\n",
       "      <td>[지자체, 의, ‘, 카카오, 채널, ’,, 도민, 관심, 부족, 으로, 폐쇄, 거...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IT/과학</td>\n",
       "      <td>[돈, 만, 잡아먹, 는, 홈페이지, ,, 과감, 게, ‘, 로그아웃, ’, 경기도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IT/과학</td>\n",
       "      <td>[콘텐츠, 기업, 대상, ‘, 부천, 클러스터, ’, 입, 주사, 모집, 경기, 콘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>정치</td>\n",
       "      <td>[안철수, ,, 독자, 출마, 로, …, 정치, 권, 배제, 채, 대권, 행보, 안...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>정치</td>\n",
       "      <td>[예, 산심, 의, 표류, …, 서민, ·, 저소득층, 울린다, 국회, 의, 예산,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>정치</td>\n",
       "      <td>[\", 퇴직금, 7000, 만, 은, 로비, 대가, \", 제기, ,, 커지, 는, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>정치</td>\n",
       "      <td>[\", 국회의원, ㆍ장관, 겸직, 금지, 면, 임명권자, 인재, 풀, 좁, 아, 져...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>정치</td>\n",
       "      <td>[민주, \", 반대, 기, 는, …, \", 국무총리실, 은, 박근혜, 대통령, 당선...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0     IT/과학  [인터넷, 게임, 족쇄, 에, 도내, 업체, 도, ‘, 덜덜, ’, 道, ㆍ업체, ...\n",
       "1     IT/과학  [삼성전자, ,, un, 에, 삼, 성만, 의, 특화, 된, 생태, 보전, 활동, ...\n",
       "2     IT/과학  [지자체, 의, ‘, 카카오, 채널, ’,, 도민, 관심, 부족, 으로, 폐쇄, 거...\n",
       "3     IT/과학  [돈, 만, 잡아먹, 는, 홈페이지, ,, 과감, 게, ‘, 로그아웃, ’, 경기도...\n",
       "4     IT/과학  [콘텐츠, 기업, 대상, ‘, 부천, 클러스터, ’, 입, 주사, 모집, 경기, 콘...\n",
       "...     ...                                                ...\n",
       "1795     정치  [안철수, ,, 독자, 출마, 로, …, 정치, 권, 배제, 채, 대권, 행보, 안...\n",
       "1796     정치  [예, 산심, 의, 표류, …, 서민, ·, 저소득층, 울린다, 국회, 의, 예산,...\n",
       "1797     정치  [\", 퇴직금, 7000, 만, 은, 로비, 대가, \", 제기, ,, 커지, 는, ...\n",
       "1798     정치  [\", 국회의원, ㆍ장관, 겸직, 금지, 면, 임명권자, 인재, 풀, 좁, 아, 져...\n",
       "1799     정치  [민주, \", 반대, 기, 는, …, \", 국무총리실, 은, 박근혜, 대통령, 당선...\n",
       "\n",
       "[1800 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNardu4-XYBF",
    "outputId": "150960ea-81fc-4bd3-e0a6-b00a61b48f41"
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors\n",
    "vectors = Vectors(name=f\"{PATH}/fasttext_morph_300.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "3aXlkqh0XYBF"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(\n",
    "    train_df.text,\n",
    "    vectors=vectors,\n",
    "    min_freq=3\n",
    ")\n",
    "vocab = TEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evdKTI4VXYBG",
    "outputId": "a540317b-97ab-4224-bae1-54ad5fdb1c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870\n"
     ]
    }
   ],
   "source": [
    "print(vocab[\"호주\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "s3ySC-ooXYBG"
   },
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Dataset, Example\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, df, fields):\n",
    "        super().__init__(\n",
    "            [Example.fromlist(list(row), fields) for i, row in df.iterrows()],\n",
    "            fields,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "J0833KPqXYBG"
   },
   "outputs": [],
   "source": [
    "fields = (\n",
    "    (\"label\", LABEL),\n",
    "    (\"text\", TEXT),\n",
    ")\n",
    "train_data, valid_data = DataFrameDataset(train_df, fields).split(split_ratio=0.8)\n",
    "test_data = DataFrameDataset(test_df, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxatkzWOrnfX",
    "outputId": "60156ccf-308f-4678-99d3-70ecc231e4d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Ufv6EyCIu45M"
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "hfC4A_mT16M7"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels = 1, \n",
    "                out_channels = n_filters, \n",
    "                kernel_size = (fs, embedding_dim),\n",
    "            ) for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):        \n",
    "        #text = [sent len, batch size]\n",
    "        text = text.permute(1, 0)\n",
    "        #text = [batch size, sent len]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "OHyYLndQXYBH"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2, 3, 4]\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0FY5W4KXYBH",
    "outputId": "bcd40a61-f3fc-47be-d0c8-f4a9f028d440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12,808,809 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnjxO_t_XYBH",
    "outputId": "dbe58b5f-ae6d-4365-e685-8c445aa168b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "2iqZaI74XYBI"
   },
   "outputs": [],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "JKQoL1ZeXYBI"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "3J9x781TXYBI"
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    top_pred = preds.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5kER5DYUXYBI"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = categorical_accuracy(predictions, batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "P4Q7a9EKXYBI"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7Hpfs6KRXYBJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - elapsed_mins * 60)\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "opB9QfPicQhn"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"newspaper-model-with-stops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "6YP_sYXQXYBK",
    "outputId": "b18adbda-b411-4226-d1e9-0ebd1dc28146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Epoch Time: 1m 28s\n",
      "\tTrain Loss: 0.341 | Train Acc: 89.08%\n",
      "\t Val. Loss: 0.610 |  Val. Acc: 78.88%\n",
      "Epoch: 12 | Epoch Time: 1m 31s\n",
      "\tTrain Loss: 0.270 | Train Acc: 91.39%\n",
      "\t Val. Loss: 0.626 |  Val. Acc: 78.88%\n",
      "Epoch: 13 | Epoch Time: 1m 31s\n",
      "\tTrain Loss: 0.215 | Train Acc: 93.43%\n",
      "\t Val. Loss: 0.623 |  Val. Acc: 79.47%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f\"{PATH}/{MODEL_NAME}.pt\")\n",
    "\n",
    "    print(f\"Epoch: {10 + epoch:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "4DXcB2jUXYBK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.575 | Test Acc: 80.06%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"{PATH}/{MODEL_NAME}.pt\"))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9zWvHr3nMmW"
   },
   "source": [
    "## User Input\n",
    "\n",
    "####  뉴스 labels\n",
    "    -  IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "AZbVnUOknMmW"
   },
   "outputs": [],
   "source": [
    "def predict_news(model, sentence, min_len=5):\n",
    "    model.eval()\n",
    "    tokenized = preprocess(sentence)\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += [\"<pad>\"] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    preds = model(tensor)\n",
    "    max_preds = preds.argmax(dim=1)\n",
    "    # print(preds)\n",
    "    return max_preds.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "gm61TN2VXYBK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예상\t답안\t정답\n",
      "스포츠\t생활\tX\n",
      "정치\t정치\tO\n",
      "사회\t경제\tX\n",
      "문화\t문화\tO\n",
      "생활\t사회\tX\n",
      "스포츠\t스포츠\tO\n",
      "문화\t연예\tX\n",
      "미용/사회\t미용/사회\tO\n",
      "IT/과학\tIT/과학\tO\n",
      "\t\t5/9=56%\n"
     ]
    }
   ],
   "source": [
    "lookup = [\"IT/과학\", \"경제\", \"문화\", \"미용/사회\", \"사회\", \"생활\", \"스포츠\", \"연예\", \"정치\"]\n",
    "sentences = [\n",
    "    \"차진 식감과 부드러운 감촉을 모두 지닌 식빵, 결결이 찢어지는 크루아상, 둥글고 크게 구운 호밀빵 모두 모양새부터 알차고 단단했다. 디저트로 눈을 옮기면 국가 대표팀같이 뭐 하나 빼놓을 수 없는 케이크가 나란히 줄을 서 있었다.\",\n",
    "    \"정부는 2012년 예산의 공고안과 배정계획을 1월3일 국무회의에서 의결하고 연초부터 바로 집행에 들어간다. 세계 경제의 불확실성이 높아지고 경기가 둔화할 가능성이 높은 만큼 조기 집행에 박차를 가할 예정이다\",\n",
    "    \"국세청은 특히 서민생활에 피해를 주면서 폭리를 취하는 매점매석 농수산물 유통업체 등에 대한 추적조사를 강화하고, 지방청에 ‘민생침해 사업자 조사전담팀’을 꾸려 민생침해 탈세자에 대한 엄정 대응에 나설 계획이라고 밝혔다\",\n",
    "    \"26일 제25회 부산국제영화제 갈라 프레젠테이션 부문 초청작 '스파이의 아내' 온라인 기자회견이 진행됐다. 작품을 연출한 구로사와 감독이 참석해 작품에 대한 이야기를 나눴다.\",\n",
    "    \"70대 운전사가 몰던 25인승 어린이 통학버스가 주유소로 돌진해 차량 3대를 들이 받았다. 다행히 통학버스에 운전자 외에는 탑승자가 없어 큰 인명피해는 피했다. 운전자는 차량 결함을 주장하고 있으나, 경찰은 운전자 과실 여부도 조사 중이다.\",\n",
    "    \"토트넘이 손흥민에게 주급 20만 파운드(약 3억원)-5년 재계약을 제안할 준비를 마쳤다.' 25일(한국시각) 영국 대중일간 더선의 헤드라인이다. 조제 무리뉴 토트넘 감독이 번리전을 앞두고 기자회견을 통해 구단에 토트넘에서의 손흥민의 장밋빛 미래를 확신하며 재계약을 요청한 직후 영국 현지 언론에선 손흥민 재계약 보도가 쏟아지고 있다.\",\n",
    "    \"공연은 말 그대로 다채로움 그 자체였다. 발레극인지, 현대무용극인지, 전통극인지, 연극인지, 연극이면 다인극인지 1인극인지 모를 정도로 다양한 장르의 결합이 먼저 눈에 띈다.\",\n",
    "    \"발이 아프면 걷는 자세가 나빠지고 자연스럽게 무릎, 골반, 허리에 이상이 생길 수 있다. 이를 예방하려면 평소 발바닥 근육을 스트레칭하고 강화하는 운동을 지속하는 게 중요하다.\",\n",
    "    \"전기차 화재 사고가 연이어 발생하는 가운데 불타지 않는 SK이노베이션 배터리가 주목받는다. SK이노베이션의 배터리는 글로벌 배터리 업체 중 유일하게 단 한건의 화재도 일어나지 않았다. 이같은 비결이 자동차 안정성을 결정짓는 분리막 내재화에 있다는 평가가 나온다.\",\n",
    "]\n",
    "# HUMAN PRED: 생활 - 경제 - 경제 - 문화 - 사회 - 스포츠 - 문화 - 미용/사회 - IT/과학\n",
    "# 5, 1, 1, 2, 4, 6, 2, 3, 0\n",
    "answers = [5, 8, 1, 2, 4, 6, 7, 3, 0]\n",
    "cnt = 0\n",
    "print(\"예상\\t답안\\t정답\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    pred = predict_news(model, sentence)\n",
    "    ans = answers[i]\n",
    "    if pred == ans:\n",
    "        cnt += 1\n",
    "    print(f\"{lookup[pred]}\\t{lookup[ans]}\\t{'O' if pred == ans else 'X'}\")\n",
    "\n",
    "print(f\"\\t\\t{cnt}/{len(answers)}={cnt / len(answers) * 100:.0f}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
